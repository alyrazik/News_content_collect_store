{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrawlingBBC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNS/8DiTQc/CKijHVEwn+9t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyrazik/News_content_collect_store/blob/MongoDB-Saving-and-querying/CrawlingBBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k33AWsna339"
      },
      "source": [
        "#  News Content Collect and Store\n",
        "## by Aly Abdelrazek\n",
        " \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79MNmsrbCR1"
      },
      "source": [
        "##Setup and Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWGf2fmJ_fT3",
        "outputId": "48c76e17-0efa-4263-95ad-6b7f96066cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m pip install pymongo[srv]"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.6/dist-packages (3.11.0)\n",
            "Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in /usr/local/lib/python3.6/dist-packages (from pymongo[srv]) (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLi3_Fort-rG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "from datetime import datetime\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBkwLD30T8Y6",
        "outputId": "39105f38-a6f0-4d17-e420-606110b025cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pymongo.version"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.11.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxOK26K5N5P"
      },
      "source": [
        "##Global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c1Y1duR5Hcn"
      },
      "source": [
        "news_page_url = \"https://bbc.com/news\"\n",
        "absolute_link_prefix = \"https://bbc.com\"\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgzHfuU3bK_N"
      },
      "source": [
        "##Crawl\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4x-otyBvPVA"
      },
      "source": [
        "# Obtains news stories links from news_page_url (https://bbc.com/news)\n",
        "def news_page_to_news_urls(url, prefix):\n",
        "    ''' Takes the URL to a news page and the prefix of the absolute link, and returns a list of news stories URLs.'''\n",
        "    news_urls = []\n",
        "    news_page_html = requests.get(url).text\n",
        "    news_page_soup = BeautifulSoup(news_page_html, \"html.parser\")\n",
        "    news_page_links = news_page_soup.findAll(\"a\") #find all links\n",
        "    \n",
        "    for link in news_page_links:\n",
        "        href = link.get(\"href\")\n",
        "        if href.startswith(\"/news\") and href[-1].isdigit(): #news articles start with /news and ends with a digit\n",
        "            news_url = prefix + href\n",
        "            s = BeautifulSoup(requests.get(news_url).text , \"html.parser\")\n",
        "            if s.find(class_= \"css-16rg7hm-ContainerWithSidebarWrapper e1jl38b40\") is not None: #this class is only available in news articles\n",
        "              news_urls.append(news_url)\n",
        "    return news_urls\n",
        "\n",
        "news_urls = news_page_to_news_urls(news_page_url, absolute_link_prefix)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLL4zU1LZxbT",
        "outputId": "efb29aef-1384-4e36-92c9-4d0800df4a47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(news_urls)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywQZnmqGFgU"
      },
      "source": [
        "## Scrape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI0CNwitGOXN"
      },
      "source": [
        "documents = []\n",
        "document_index = 0\n",
        "\n",
        "for url in news_urls:\n",
        "    print(\"Fetching {}\".format(url))\n",
        "    response = requests.get(url)\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    news_heading = (soup.find('h1')).text\n",
        "    news_text = [p.text for p in soup.find('article').find_all('p')]\n",
        "    news_time = (soup.find('time'))['datetime']\n",
        "\n",
        "    documents.append({\"Document_Index\":str(document_index), \"Heading\":news_heading, \"Text\":news_text, \"DateTime\":news_time})\n",
        "    document_index = document_index+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqVGWvWp41-_"
      },
      "source": [
        "##Saving to MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uu-mCu7ODkN"
      },
      "source": [
        "#connect to client\n",
        "client = MongoClient(\"mongodb+srv://aly:a@cluster0.4pfcp.mongodb.net/db?retryWrites=true&w=majority\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLK-yYU4-sZ"
      },
      "source": [
        "#create a database\n",
        "db = client[\"news_database\"]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ0ItLqP5Erh"
      },
      "source": [
        "#create a collection (a table)\n",
        "bbc_news = db[\"bbc_news\"]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbRwByOM1G0D",
        "outputId": "bb506f5c-53bf-4546-e378-e5b33681b788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "db['bbc_news'].delete_many({})"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.DeleteResult at 0x7fc33bb50d08>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGtZS6q5fQs",
        "outputId": "efc7f66f-9e5c-481b-8002-5ef620944b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bbc_news.insert_many(documents)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.InsertManyResult at 0x7fc33a339148>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaC7v2DIdDLm"
      },
      "source": [
        "##Retrieving content from MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHFqIvw7Dh9_"
      },
      "source": [
        "def retrieve_documents(database, collection):\n",
        "  '''takes a MongoDB database and collection name, and returns all documents in collection to a pandas dataframe'''\n",
        "  retrieved_documents = database[collection].find() #do not use database.collection, it is a string :)\n",
        "  retrieved_df = pd.DataFrame(retrieved_documents)\n",
        "  return retrieved_df\n",
        "\n",
        "db = client[\"news_database\"]\n",
        "df = retrieve_documents(database = db , collection = 'bbc_news')"
      ],
      "execution_count": 130,
      "outputs": []
    }
  ]
}