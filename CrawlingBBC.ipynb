{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrawlingBBC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmi7m9pnPSwcntOvBl9eW0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyrazik/News_content_collect_store/blob/main/CrawlingBBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k33AWsna339"
      },
      "source": [
        "#  News Content Collect and Store\n",
        "## by Aly Abdelrazek\n",
        " \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79MNmsrbCR1"
      },
      "source": [
        "##Setup and Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWGf2fmJ_fT3",
        "outputId": "2a075d26-a823-4dc4-8dad-f3309b5ef342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m pip install pymongo[srv]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.6/dist-packages (3.11.0)\n",
            "Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in /usr/local/lib/python3.6/dist-packages (from pymongo[srv]) (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLi3_Fort-rG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "from datetime import datetime\n",
        "import time\n",
        "from time import sleep\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBkwLD30T8Y6",
        "outputId": "9ec9cb28-72b2-455c-b52f-086a2c88024c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pymongo.version"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.11.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxOK26K5N5P"
      },
      "source": [
        "##Global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c1Y1duR5Hcn"
      },
      "source": [
        "news_page_url = \"https://bbc.com/news\"\n",
        "parent = \"https://bbc.com\"\n",
        "SEARCH_LIMIT = 10   #limit the number of returned articles matching a keyword search\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgzHfuU3bK_N"
      },
      "source": [
        "##Crawl\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4x-otyBvPVA"
      },
      "source": [
        "# Obtains a list of links from a page_url\n",
        "\n",
        "def give_links(url, parent):\n",
        "  ''' Take a url, and its parent address and returns a list of absolute addresses of web links orginitating from it.'''\n",
        "  \n",
        "  page_html = requests.get(url).text\n",
        "  page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
        "  page_links = page_soup.findAll(\"a\") #find all links\n",
        "\n",
        "  #validate and process obtained links\n",
        "  output1 = [link.get(\"href\") for link in page_links if link.get(\"href\") is not None]\n",
        "  output2 = [parent+link if link.startswith(\"/news\") else link for link in output1]\n",
        "  output3 = [link for link in output2 if \"http\" in link]\n",
        "\n",
        "\n",
        "  return output3\n",
        " \n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQW_9PtMDXEo"
      },
      "source": [
        "\n",
        "def is_news_article(link):\n",
        "  ''' \n",
        "  Take a web link address and tests whether the link contains a news article in BBC. Returns 1 if True, 0 otherwise.  \n",
        "  ''' \n",
        "  if \"/news\" in link: #news articles have /news in address. if not, it is considered not a news article.\n",
        "\n",
        "    try:\n",
        "      s = BeautifulSoup(requests.get(link).text , \"html.parser\")\n",
        "      if s.find(class_= \"css-16rg7hm-ContainerWithSidebarWrapper e1jl38b40\") is not None: #this class is only available in news articles\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"Connection to page refused\")\n",
        "    except:\n",
        "        print(\"An error occured while trying to connect to link\")\n",
        "    else:\n",
        "        print(\"Parsing successful\")\n",
        "  return 0\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHMU4GySy0wy"
      },
      "source": [
        "def follow_links(origin_link, test_func, n_other_links_to_follow = 1):\n",
        "  '''\n",
        "  Takes a link and starts following all links it contained searching for a pattern specificed by boolean function test_func. It adds them to matching_urls list. \n",
        "  Other links that doesn't match the specified pattern are added to another list (other_urls). The function will then crawl a number of them specified by n_other_links_to_follow.\n",
        "  Args:\n",
        "    -origin link: a string of the URL address (<string>)\n",
        "    -test_func: a callable that takes a string of a URL link and outputs 1 if the link matches a specified pattern, 0 otherwise.\n",
        "    -n_other_links_to_follow : number of links to follow from the other_urls list (<int>)\n",
        "  Returns:\n",
        "    -Two python lists containing matching_urls and other_urls\n",
        "  '''\n",
        "  matching_urls = []\n",
        "  other_urls = [origin_link]\n",
        "\n",
        "  start_time = time.time()\n",
        "  print(\"following links...\")\n",
        "  \n",
        "  for i in range(n_other_links_to_follow):\n",
        "    links = give_links(other_urls[i], parent)\n",
        "    other_urls.pop(0) #no longer needed\n",
        "    matching_urls = matching_urls + [link for link in links if (test_func(link))]\n",
        "    other_urls = other_urls + [link for link in links if link not in matching_urls]\n",
        "    other_urls = list(dict.fromkeys(other_urls)) #remove duplicates from list.\n",
        "\n",
        "  end_time = time.time()\n",
        "  execution_time = end_time - start_time\n",
        "  print(\"completed in {:2f} seconds\".format(execution_time))\n",
        "\n",
        "  matching_urls = list(dict.fromkeys(matching_urls)) #remove duplicates from the list\n",
        "  \n",
        "  return matching_urls, other_urls"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2s4gbOBJLzm",
        "outputId": "55e107d1-a1ed-43dc-fcc5-94b7c0465335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "news_urls, other_urls = follow_links(news_page_url, is_news_article)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "following links...\n",
            "completed in 78.790332 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sknD-wND12Ut",
        "outputId": "50d98b00-72a7-4a51-a3dc-ddec1cc98a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(news_urls)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33PWrDiS19BN",
        "outputId": "59be1287-be29-4ed3-94ac-f831f81d2036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(other_urls)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywQZnmqGFgU"
      },
      "source": [
        "## Scrape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI0CNwitGOXN",
        "outputId": "bd1a269e-03c4-49f9-90e4-8b857f636f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "documents = []\n",
        "document_index = 0\n",
        "\n",
        "for url in news_urls:\n",
        "    print(\"Fetching {}\".format(url))\n",
        "    response = requests.get(url)\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    news_heading = (soup.find('h1')).text\n",
        "    news_text = [p.text for p in soup.find('article').find_all('p')]\n",
        "    news_time = (soup.find('time'))['datetime']\n",
        "\n",
        "    documents.append({\"Document_Index\":str(document_index), \"URL\":url, \"Heading\":news_heading, \"Article\":news_text, \"DateTime\":news_time})\n",
        "    document_index = document_index+1\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching https://bbc.com/news/election-us-2020-54756915\n",
            "Fetching https://bbc.com/news/election-us-2020-53657174\n",
            "Fetching https://bbc.com/news/world-us-canada-54665375\n",
            "Fetching https://bbc.com/news/world-us-canada-54751759\n",
            "Fetching https://bbc.com/news/world-europe-54759443\n",
            "Fetching https://bbc.com/news/uk-54756950\n",
            "Fetching https://bbc.com/news/uk-northern-ireland-54750668\n",
            "Fetching https://bbc.com/news/world-europe-54747022\n",
            "Fetching https://bbc.com/news/world-us-canada-54752228\n",
            "Fetching https://bbc.com/news/world-africa-54733425\n",
            "Fetching https://bbc.com/news/world-europe-54752194\n",
            "Fetching https://bbc.com/news/uk-54759343\n",
            "Fetching https://bbc.com/news/election-us-2020-54731172\n",
            "Fetching https://bbc.com/news/election-us-2020-54736083\n",
            "Fetching https://bbc.com/news/world-54553132\n",
            "Fetching https://bbc.com/news/uk-wales-54692567\n",
            "Fetching https://bbc.com/news/world-europe-54747020\n",
            "Fetching https://bbc.com/news/world-asia-54717686\n",
            "Fetching https://bbc.com/news/health-54661843\n",
            "Fetching https://bbc.com/news/world-asia-54097609\n",
            "Fetching https://bbc.com/news/world-asia-india-54655948\n",
            "Fetching https://bbc.com/news/business-54549612\n",
            "Fetching https://www.bbc.co.uk/news/stories-54623417\n",
            "Fetching https://www.bbc.co.uk/news/stories-54613947\n",
            "Fetching https://bbc.com/news/world-asia-india-54759863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqVGWvWp41-_"
      },
      "source": [
        "##Saving to MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uu-mCu7ODkN"
      },
      "source": [
        "#connect to client\n",
        "client = MongoClient(\"mongodb+srv://aly:a@cluster0.4pfcp.mongodb.net/db?retryWrites=true&w=majority\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLK-yYU4-sZ"
      },
      "source": [
        "#create a database\n",
        "db = client[\"news_database\"]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ0ItLqP5Erh"
      },
      "source": [
        "#create a collection (a table)\n",
        "bbc_news = db[\"bbc_news\"]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbRwByOM1G0D",
        "outputId": "807fb6d0-611d-4b95-9392-798e3345afc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "db['bbc_news'].delete_many({})"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.DeleteResult at 0x7ff388696788>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGtZS6q5fQs",
        "outputId": "204960fd-0523-4569-bbae-b7dd44095b8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bbc_news.insert_many(documents)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.InsertManyResult at 0x7ff3886be788>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaC7v2DIdDLm"
      },
      "source": [
        "##Retrieving content from MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHFqIvw7Dh9_"
      },
      "source": [
        "def retrieve_documents(database, collection):\n",
        "  ''' Take a MongoDB database and collection name, and returns all documents in collection to a pandas dataframe'''\n",
        "  retrieved_documents = database[collection].find() #do not use database.collection, it is a string :)\n",
        "  retrieved_df = pd.DataFrame(retrieved_documents)\n",
        "  return retrieved_df\n",
        "\n",
        "db = client[\"news_database\"]\n",
        "df = retrieve_documents(database = db , collection = 'bbc_news')"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH9F8tp827ZE"
      },
      "source": [
        "## Keyword search in article text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj1uAarhj5cV"
      },
      "source": [
        "####Create a text index -required for text search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDjgxscP4SLd",
        "outputId": "e6d336da-10bd-4ff5-9a4c-6be89e127c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "db = client[\"news_database\"]\n",
        "db.bbc_news.create_index([\n",
        "          (\"Article\", \"text\"),\n",
        "          (\"Heading\", \"text\"),\n",
        "  ],\n",
        "  name=\"search_index\",\n",
        "  weights={\n",
        "      'Article':25,\n",
        "      'Heading':100\n",
        "  }\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'search_index'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZSO_1j7kEZd"
      },
      "source": [
        "#### Search function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jK70SV_35zg"
      },
      "source": [
        "def search(search_text, database, collection):\n",
        "  '''\n",
        "  Take a a string containing keywords and outputs all relevant articles to any of them\n",
        "  Args:\n",
        "    -search_text: a string of keywords (<string>)\n",
        "    -database: MongoDB database name (<pymongo.database.Database>)\n",
        "    -collection: string with the name of MongoDB collection (<string>)\n",
        "  Returns:\n",
        "    -A pandas dataframe containing the MongoDB contents of the returned news articles\n",
        "  '''\n",
        "  returned_cursor = database[collection].find({\"$text\": {\"$search\": search_text}}).limit(SEARCH_LIMIT)\n",
        "  df = pd.DataFrame(returned_cursor)\n",
        "  return df\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XivlBnuGTV9N"
      },
      "source": [
        "output = search(\"indian\", db, 'bbc_news')"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du0fqsNWTaXu",
        "outputId": "1a210b44-107b-463f-c631-555b134c2199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output['URL']"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    https://bbc.com/news/world-asia-india-54759863\n",
              "1    https://bbc.com/news/world-asia-india-54655948\n",
              "2       https://www.bbc.co.uk/news/stories-54623417\n",
              "Name: URL, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsirTLxnU0kS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}