{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrawlingBBC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTkaE+YZpbejeEVUzaUQQQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k33AWsna339"
      },
      "source": [
        "#  News Content Collect and Store\n",
        "## by Aly Abdelrazek\n",
        " \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79MNmsrbCR1"
      },
      "source": [
        "##Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLi3_Fort-rG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxOK26K5N5P"
      },
      "source": [
        "##Global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c1Y1duR5Hcn"
      },
      "source": [
        "news_page_url = \"https://bbc.com/news\"\n",
        "absolute_link_prefix = \"https://bbc.com\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgzHfuU3bK_N"
      },
      "source": [
        "##Scrape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4x-otyBvPVA"
      },
      "source": [
        "# Obtains news stories links from news_page_url (https://bbc.com/news)\n",
        "def news_page_to_news_urls(url, prefix):\n",
        "    ''' Takes the URL to a news page and the prefix of the absolute link, and returns a list of news stories URLs.'''\n",
        "    news_urls = []\n",
        "    news_page_html = requests.get(url).text\n",
        "    news_page_soup = BeautifulSoup(news_page_html, \"html.parser\")\n",
        "    news_page_links = news_page_soup.findAll(\"a\") #find all links\n",
        "    \n",
        "    for link in news_page_links:\n",
        "        href = link.get(\"href\")\n",
        "        if href.startswith(\"/news\") and href[-1].isdigit(): #news articles start with /news and ends with a digit\n",
        "            news_url = prefix + href\n",
        "            s = BeautifulSoup(requests.get(news_url).text , \"html.parser\")\n",
        "            if s.find(class_= \"css-16rg7hm-ContainerWithSidebarWrapper e1jl38b40\") is not None: #this class is only available in news articles\n",
        "              news_urls.append(news_url)\n",
        "    return news_urls\n",
        "\n",
        "news_urls = news_page_to_news_urls(news_page_url, absolute_link_prefix)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywQZnmqGFgU"
      },
      "source": [
        "## Cleanse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI0CNwitGOXN"
      },
      "source": [
        "news_headings = []\n",
        "news_texts =[]\n",
        "news_times = []\n",
        "\n",
        "for url in news_urls:\n",
        "    print(\"Fetching {}\".format(url))\n",
        "    response = requests.get(url)\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    news_heading = (soup.find('h1')).text\n",
        "    news_text = [p.text for p in soup.find('article').find_all('p')]\n",
        "    news_time = (soup.find('time'))['datetime']\n",
        "\n",
        "    news_headings.append(news_heading)\n",
        "    news_times.append(np.datetime64(news_time)) \n",
        "    news_texts.append(news_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSejefY0K1FL"
      },
      "source": [
        "df = pd.DataFrame(list(zip(news_times, news_headings, news_texts)), \n",
        "                  columns =['datetime', 'heading', 'text']) "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uu-mCu7ODkN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}