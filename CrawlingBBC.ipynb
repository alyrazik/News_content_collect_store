{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrawlingBBC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKGvYm45rZE3mb8G8yDX48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyrazik/News_content_collect_store/blob/main/CrawlingBBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k33AWsna339"
      },
      "source": [
        "#  News Content Collect and Store\n",
        "## by Aly Abdelrazek\n",
        "###### alyrazik@gmail.com\n",
        "\n",
        " \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylMNhAFBUQfS"
      },
      "source": [
        "A solution that crawls for articles from the bbc.com, cleanses the response, stores it in a mongo database, then makes it available to search via an API.\n",
        "\n",
        "The file contains the API code and some code applying it.\n",
        "\n",
        "Several functions provides some abstraction and allows for re-use.\n",
        "\n",
        "1. give_links(url, parent): Takes a url, and its parent address and returns a list of absolute addresses of web links orginitating from it.\n",
        "\n",
        "2. is_news_article(link):  Takes a web link address and tests whether the link contains a news article in BBC. Returns 1 if True, 0 otherwise.  \n",
        "\n",
        "3. follow_links(origin_link, test_func, n_other_links_to_follow = 1): Takes a link and starts following all links it contained searching for a pattern specificed by boolean function test_func. It adds them to matching_urls list. Other links that doesn't match the specified pattern are added to another list (other_urls). The function will then crawl a number of them specified by another function parameter.\n",
        "\n",
        "4. retrieve_documents(database, collection): Takes a MongoDB database and collection name, and returns all documents in collection to a pandas dataframe.\n",
        "\n",
        "5. search(search_text, database, collection): Takes a a string containing keywords and outputs all relevant articles to any of them.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79MNmsrbCR1"
      },
      "source": [
        "##Setup and Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWGf2fmJ_fT3",
        "outputId": "6cc4b5bd-fd23-4356-c410-e9f346b43f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m pip install pymongo[srv]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.6/dist-packages (3.11.0)\n",
            "Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in /usr/local/lib/python3.6/dist-packages (from pymongo[srv]) (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLi3_Fort-rG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "from datetime import datetime\n",
        "import time\n",
        "from time import sleep\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBkwLD30T8Y6",
        "outputId": "db4a78e4-c759-4c5f-ecc2-9bf1d17098df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pymongo.version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.11.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxOK26K5N5P"
      },
      "source": [
        "##Global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c1Y1duR5Hcn"
      },
      "source": [
        "news_page_url = \"https://bbc.com/news\"\n",
        "parent = \"https://bbc.com\"\n",
        "SEARCH_LIMIT = 10   #limit the number of returned articles matching a keyword search\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgzHfuU3bK_N"
      },
      "source": [
        "##Crawl\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4x-otyBvPVA"
      },
      "source": [
        "# Obtains a list of links from a page_url\n",
        "\n",
        "def give_links(url, parent):\n",
        "  ''' Take a url, and its parent address and returns a list of absolute addresses of web links orginitating from it.'''\n",
        "  \n",
        "  page_html = requests.get(url).text\n",
        "  page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
        "  page_links = page_soup.findAll(\"a\") #find all links\n",
        "\n",
        "  #validate and process obtained links\n",
        "  output1 = [link.get(\"href\") for link in page_links if link.get(\"href\") is not None]\n",
        "  output2 = [parent+link if link.startswith(\"/news\") else link for link in output1]\n",
        "  output3 = [link for link in output2 if \"http\" in link]\n",
        "\n",
        "\n",
        "  return output3\n",
        " \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQW_9PtMDXEo"
      },
      "source": [
        "\n",
        "def is_news_article(link):\n",
        "  ''' \n",
        "  Take a web link address and tests whether the link contains a news article in BBC. Returns 1 if True, 0 otherwise.  \n",
        "  ''' \n",
        "  if \"/news\" in link: #news articles have /news in address. if not, it is considered not a news article.\n",
        "\n",
        "    try:\n",
        "      s = BeautifulSoup(requests.get(link).text , \"html.parser\")\n",
        "      if s.find(class_= \"css-16rg7hm-ContainerWithSidebarWrapper e1jl38b40\") is not None: #this class is only available in news articles\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"Connection to page refused\")\n",
        "    except:\n",
        "        print(\"An error occured while trying to connect to link\")\n",
        "    else:\n",
        "        print(\"Parsing successful\")\n",
        "  return 0\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHMU4GySy0wy"
      },
      "source": [
        "def follow_links(origin_link, test_func, n_other_links_to_follow = 1):\n",
        "  '''\n",
        "  Takes a link and starts following all links it contained searching for a pattern specificed by boolean function test_func. It adds them to matching_urls list. \n",
        "  Other links that doesn't match the specified pattern are added to another list (other_urls). The function will then crawl a number of them specified by n_other_links_to_follow.\n",
        "  Args:\n",
        "    -origin link: a string of the URL address (<string>)\n",
        "    -test_func: a callable that takes a string of a URL link and outputs 1 if the link matches a specified pattern, 0 otherwise.\n",
        "    -n_other_links_to_follow : number of links to follow from the other_urls list (<int>)\n",
        "  Returns:\n",
        "    -Two python lists containing matching_urls and other_urls\n",
        "  '''\n",
        "  matching_urls = []\n",
        "  other_urls = [origin_link]\n",
        "\n",
        "  start_time = time.time()\n",
        "  print(\"following links...\")\n",
        "  \n",
        "  for i in range(n_other_links_to_follow):\n",
        "    links = give_links(other_urls[i], parent)\n",
        "    other_urls.pop(0) #no longer needed\n",
        "    matching_urls = matching_urls + [link for link in links if (test_func(link))]\n",
        "    other_urls = other_urls + [link for link in links if link not in matching_urls]\n",
        "    other_urls = list(dict.fromkeys(other_urls)) #remove duplicates from list.\n",
        "\n",
        "  end_time = time.time()\n",
        "  execution_time = end_time - start_time\n",
        "  print(\"completed in {:2f} seconds\".format(execution_time))\n",
        "\n",
        "  matching_urls = list(dict.fromkeys(matching_urls)) #remove duplicates from the list\n",
        "  \n",
        "  return matching_urls, other_urls"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2s4gbOBJLzm",
        "outputId": "43bde4b0-002a-4cf7-a160-a308d13ca0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "news_urls, other_urls = follow_links(news_page_url, is_news_article)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "following links...\n",
            "completed in 96.956813 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sknD-wND12Ut",
        "outputId": "ce462dd0-7c65-4408-87b4-5e1afae66a47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(news_urls)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33PWrDiS19BN",
        "outputId": "f7fb05a9-15d2-487a-d243-971eccb4bac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(other_urls)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywQZnmqGFgU"
      },
      "source": [
        "## Scrape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI0CNwitGOXN",
        "outputId": "c36751f2-b92f-4385-a4fc-f5e532201eb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "documents = []\n",
        "document_index = 0\n",
        "\n",
        "for url in news_urls:\n",
        "    print(\"Fetching {}\".format(url))\n",
        "    response = requests.get(url)\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    news_heading = (soup.find('h1')).text\n",
        "    news_text = [p.text for p in soup.find('article').find_all('p')]\n",
        "    news_time = (soup.find('time'))['datetime']\n",
        "\n",
        "    documents.append({\"Document_Index\":str(document_index), \"URL\":url,\"Heading\":news_heading, \"Article\":news_text, \"DateTime\":news_time})\n",
        "    document_index = document_index+1\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching https://bbc.com/news/uk-politics-54757446\n",
            "Fetching https://bbc.com/news/business-54751632\n",
            "Fetching https://bbc.com/news/health-54661843\n",
            "Fetching https://bbc.com/news/entertainment-arts-54761824\n",
            "Fetching https://bbc.com/news/world-asia-54097609\n",
            "Fetching https://bbc.com/news/world-asia-54717686\n",
            "Fetching https://bbc.com/news/world-asia-india-54655948\n",
            "Fetching https://bbc.com/news/uk-northern-ireland-54750668\n",
            "Fetching https://bbc.com/news/world-europe-54760766\n",
            "Fetching https://bbc.com/news/world-asia-54759868\n",
            "Fetching https://bbc.com/news/world-europe-54763136\n",
            "Fetching https://bbc.com/news/uk-54759343\n",
            "Fetching https://bbc.com/news/election-us-2020-54736083\n",
            "Fetching https://bbc.com/news/election-us-2020-53657174\n",
            "Fetching https://bbc.com/news/technology-54738873\n",
            "Fetching https://bbc.com/news/business-54549612\n",
            "Fetching https://bbc.com/news/entertainment-arts-41523800\n",
            "Fetching https://bbc.com/news/uk-wales-54692567\n",
            "Fetching https://bbc.com/news/world-asia-india-54688795\n",
            "Fetching https://bbc.com/news/entertainment-arts-13087132\n",
            "Fetching https://bbc.com/news/science-environment-54723147\n",
            "Fetching https://bbc.com/news/world-europe-54747022\n",
            "Fetching https://bbc.com/news/world-us-canada-54756044\n",
            "Fetching https://bbc.com/news/world-asia-54697454\n",
            "Fetching https://bbc.com/news/world-asia-54701279\n",
            "Fetching https://bbc.com/news/world-africa-54692210\n",
            "Fetching https://bbc.com/news/uk-54763956\n",
            "Fetching https://bbc.com/news/world-asia-india-54759863\n",
            "Fetching https://bbc.com/news/world-europe-54764000\n",
            "Fetching https://bbc.com/news/54763682\n",
            "Fetching https://bbc.com/news/world-africa-54762884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqVGWvWp41-_"
      },
      "source": [
        "##Saving to MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uu-mCu7ODkN"
      },
      "source": [
        "#connect to client\n",
        "client = MongoClient(\"mongodb+srv://aly:a@cluster0.4pfcp.mongodb.net/db?retryWrites=true&w=majority\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLK-yYU4-sZ"
      },
      "source": [
        "#create a database\n",
        "db = client[\"news_database\"]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ0ItLqP5Erh"
      },
      "source": [
        "#create a collection (a table)\n",
        "bbc_news = db[\"bbc_news\"]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbRwByOM1G0D",
        "outputId": "7d6953a7-b9ca-43f9-85ab-aaad337aba18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "db['bbc_news'].delete_many({})"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.DeleteResult at 0x7f08253a9448>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGtZS6q5fQs",
        "outputId": "d9cb204c-bc25-4675-94b2-cefa8edb1c4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bbc_news.insert_many(documents)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.InsertManyResult at 0x7f08253a9908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaC7v2DIdDLm"
      },
      "source": [
        "##Retrieving content from MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHFqIvw7Dh9_"
      },
      "source": [
        "def retrieve_documents(database, collection):\n",
        "  ''' Take a MongoDB database and collection name, and returns all documents in collection to a pandas dataframe'''\n",
        "  retrieved_documents = database[collection].find() #do not use database.collection, it is a string :)\n",
        "  retrieved_df = pd.DataFrame(retrieved_documents)\n",
        "  return retrieved_df\n",
        "\n",
        "db = client[\"news_database\"]\n",
        "df = retrieve_documents(database = db , collection = 'bbc_news')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3XItc8BTwFx",
        "outputId": "f7f6b420-6d33-46d8-960d-81b8997a6d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>Document_Index</th>\n",
              "      <th>URL</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Article</th>\n",
              "      <th>DateTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f9dc6cb662b4d38a5b8cff6</td>\n",
              "      <td>0</td>\n",
              "      <td>https://bbc.com/news/uk-politics-54757446</td>\n",
              "      <td>Covid-19: The documents pushing Johnson to act</td>\n",
              "      <td>[.css-nxqgwe-ImageWrapper{-webkit-flex:none;-m...</td>\n",
              "      <td>2020-10-31T06:00:05.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5f9dc6cb662b4d38a5b8cff7</td>\n",
              "      <td>1</td>\n",
              "      <td>https://bbc.com/news/business-54751632</td>\n",
              "      <td>'A new lockdown will be far worse for businesses'</td>\n",
              "      <td>[By Mary-Ann RussonBusiness reporter, BBC News...</td>\n",
              "      <td>2020-10-31T13:25:09.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5f9dc6cb662b4d38a5b8cff8</td>\n",
              "      <td>2</td>\n",
              "      <td>https://bbc.com/news/health-54661843</td>\n",
              "      <td>Covid: When will it be over and we can do this...</td>\n",
              "      <td>[By James GallagherHealth and science correspo...</td>\n",
              "      <td>2020-10-31T00:22:42.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5f9dc6cb662b4d38a5b8cff9</td>\n",
              "      <td>3</td>\n",
              "      <td>https://bbc.com/news/entertainment-arts-54761824</td>\n",
              "      <td>Sean Connery: James Bond actor dies aged 90</td>\n",
              "      <td>[.css-14iz86j-BoldText{font-weight:bold;}Sir S...</td>\n",
              "      <td>2020-10-31T17:24:49.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5f9dc6cb662b4d38a5b8cffa</td>\n",
              "      <td>4</td>\n",
              "      <td>https://bbc.com/news/world-asia-54097609</td>\n",
              "      <td>US election 2020: The Asians who are rooting f...</td>\n",
              "      <td>[By Andreas IllmerBBC News, .css-14iz86j-BoldT...</td>\n",
              "      <td>2020-10-31T01:31:24.000Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id  ...                  DateTime\n",
              "0  5f9dc6cb662b4d38a5b8cff6  ...  2020-10-31T06:00:05.000Z\n",
              "1  5f9dc6cb662b4d38a5b8cff7  ...  2020-10-31T13:25:09.000Z\n",
              "2  5f9dc6cb662b4d38a5b8cff8  ...  2020-10-31T00:22:42.000Z\n",
              "3  5f9dc6cb662b4d38a5b8cff9  ...  2020-10-31T17:24:49.000Z\n",
              "4  5f9dc6cb662b4d38a5b8cffa  ...  2020-10-31T01:31:24.000Z\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH9F8tp827ZE"
      },
      "source": [
        "## Keyword search in article text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj1uAarhj5cV"
      },
      "source": [
        "####Create a text index -required for text search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDjgxscP4SLd",
        "outputId": "6bee79bb-f05c-4cd2-958f-a8d0a5e6f4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "db = client[\"news_database\"]\n",
        "db.bbc_news.create_index([\n",
        "          (\"Article\", \"text\"),\n",
        "          (\"Heading\", \"text\"),\n",
        "  ],\n",
        "  name=\"search_index\",\n",
        "  weights={\n",
        "      'Article':25,\n",
        "      'Heading':100\n",
        "  }\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'search_index'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZSO_1j7kEZd"
      },
      "source": [
        "#### Search function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jK70SV_35zg"
      },
      "source": [
        "def search(search_text, database, collection):\n",
        "  '''\n",
        "  Take a a string containing keywords and outputs all relevant articles to any of them\n",
        "  Args:\n",
        "    -search_text: a string of keywords (<string>)\n",
        "    -database: MongoDB database name (<pymongo.database.Database>)\n",
        "    -collection: string with the name of MongoDB collection (<string>)\n",
        "  Returns:\n",
        "    -A pandas dataframe containing the MongoDB contents of the returned news articles\n",
        "  '''\n",
        "  returned_cursor = database[collection].find({\"$text\": {\"$search\": search_text}}).limit(SEARCH_LIMIT)\n",
        "  df = pd.DataFrame(returned_cursor)\n",
        "  return df\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XivlBnuGTV9N"
      },
      "source": [
        "output = search(\"indian\", db, 'bbc_news')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du0fqsNWTaXu",
        "outputId": "df08986b-7a94-437c-b52f-145d879a42d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output['URL']"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    https://bbc.com/news/world-asia-india-54688795\n",
              "1    https://bbc.com/news/world-asia-india-54759863\n",
              "2        https://bbc.com/news/world-africa-54692210\n",
              "3    https://bbc.com/news/world-asia-india-54655948\n",
              "4          https://bbc.com/news/world-asia-54701279\n",
              "Name: URL, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsirTLxnU0kS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}